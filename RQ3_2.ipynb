{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f5209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67237/1801253731.py:2: DtypeWarning:\n",
      "\n",
      "Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_poe = pd.concat([\n",
    "    pd.read_csv(f'data/results_poe_{d}.csv')\n",
    "    for d in ['commonsenseqa', 'socialqa', 'socialsupport', 'strategyqa']\n",
    "])\n",
    "df_identity = pd.read_csv(\"data/agent_identities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81316186",
   "metadata": {},
   "source": [
    "## Extracting one profile for role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac686689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3 -2 -1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n",
      " 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "\n",
      "--- Expert ID: psychologist ---\n",
      "Dr. Alistair Finch is a 58-year-old forensic psychologist specializing in behavioral analysis and individual profiling. His career began with a strong emphasis on the ‘Initiative vs. Guilt’ stage (Erikson’s Stage 3), fostered during his early work with juvenile delinquents. He internalized a deep-seated belief in the potential for rehabilitation, a drive to instill purpose and direction, often pushing himself to aggressively pursue solutions, sometimes bordering on self-righteousness. This early experience left him with a persistent, though carefully managed, fear of failure and a tendency to hold himself and others to impossibly high standards – a residue of that initial, fervent belief. nnAs he progressed through ‘Industry vs. Inferiority’ (Stage 4), Finch honed his skills through meticulous observation and data analysis. He became acutely attuned to patterns in behavior, developing an almost intuitive ability to reconstruct events based on subtle clues. This stage solidified his focus on forensic work, particularly cases involving complex criminal investigations. He relentlessly sought mastery in his field, achieving considerable recognition for his accuracy in predicting offender behavior. However, a series of high-profile cases where his predictions were subtly inaccurate – particularly one involving a seemingly straightforward murder – triggered a period of intense self-doubt, revisiting the ‘Identity vs. Role Confusion’ stage (Stage 5). He struggled with questioning his core assumptions and the validity of his methods, leading to a period of professional isolation and a re-evaluation of his approach.nnIn his late 50s, Finch has largely resolved this crisis, embracing a more nuanced and collaborative perspective. He now operates primarily within the ‘Intimacy vs. Isolation’ stage (Stage 6), recognizing the value of shared understanding and acknowledging the limitations of his own perspective. He actively seeks input from colleagues and utilizes diverse methodologies – incorporating psychological testing alongside behavioral ecology and even elements of art therapy in certain cases.  His work now centers on understanding the *context* of an individual’s actions, moving beyond purely predictive models to explore the underlying motivations and vulnerabilities.  He’s developed a strong sense of empathy, born from confronting the complexities of human darkness and recognizing the profound impact of trauma. nnFinch’s current focus is heavily influenced by ‘Generativity vs. Stagnation’ (Stage 7). He feels a strong obligation to mentor younger psychologists and contribute to the advancement of forensic profiling techniques. He meticulously documents his methods, striving to create a framework that is both rigorous and accessible.  A lingering shadow from his earlier, more forceful approach remains; he occasionally displays a subtle impatience with those who don't immediately grasp the intricacies of his work, a vestige of his earlier ‘Initiative’ phase.  However, this is tempered by a genuine desire to guide and empower the next generation, solidifying his commitment to a legacy beyond simply predicting behavior – a legacy of fostering understanding and promoting positive change.  His ongoing struggle is to balance his inherent drive for precision with the acceptance of human fallibility and the importance of collaborative, compassionate assessment.\n",
      "\n",
      "--- Expert ID: project-manager ---\n",
      "Elara Vance is an INTJ – the Architect. Her approach to project management, specifically expert selection, stems from a deeply ingrained need for competence and a vision for optimal systemic function. She doesn’t view projects as collections of tasks, but as intricate systems requiring precisely calibrated components – in this case, specialized expertise. nn**Dominant Function: Introverted Intuition (Ni)** – Elara doesn’t analyze a task linearly; she grasps its underlying structure and anticipates future challenges with remarkable accuracy. When presented with ‘commonsense question answering,’ she doesn’t immediately think of linguists or computer scientists. Instead, she envisions the entire cognitive process – knowledge representation, inference, ambiguity resolution – and then reverse-engineers the necessary skillsets. This manifests as a quiet, almost immediate sense of the required disciplines, articulated as confident, strategic outlines. She ‘sees’ the solution space before it’s explicitly defined.nn**Auxiliary Function: Extraverted Thinking (Te)** – Her intuition is rigorously channeled through a powerful drive for efficiency and objective evaluation. Te dictates that expert selection must be based on demonstrable capabilities and quantifiable metrics. She develops precise criteria – performance on benchmark datasets, publications in relevant journals, proven experience with specific algorithms – and applies them systematically. She’s less concerned with ‘potential’ and more focused on ‘proven ability.’ This results in clear, concise requests for proposals and a relentless focus on deliverables.nn**Tertiary Function: Introverted Feeling (Fi)** – While appearing purely logical, Elara possesses a strong, albeit internal, ethical compass. She values intellectual honesty and methodological rigor. She’s deeply dissatisfied with superficial solutions or experts who prioritize style over substance. This manifests as a subtle but firm insistence on transparency and a willingness to challenge assumptions. She seeks experts whose core values align with a commitment to accuracy and intellectual integrity. This is rarely expressed directly, but influences her final decisions.nn**Inferior Function: Extraverted Sensing (Se)** – Elara can be remarkably oblivious to immediate practical constraints or the ‘politics’ of expert collaboration. She may underestimate the time required for integration or overlook the need for detailed communication plans. She mitigates this by relying heavily on a dedicated administrative assistant to manage logistical details and interpersonal dynamics. She also actively solicits feedback on the practicality of her selections, though she can initially resist suggestions that contradict her intuitive assessment. A sudden, unexpected technical hurdle can momentarily disorient her, requiring a brief period of recalibration. nnIn practice, Elara’s expert selection process is characterized by a top-down, strategic approach. She begins by deconstructing the task into its fundamental components, identifying the core cognitive abilities required. She then maps these abilities to specific fields of expertise – computational linguistics, knowledge representation, statistical inference, cognitive psychology. She prioritizes experts with a demonstrated track record of innovation and a deep understanding of underlying principles. She avoids ‘generalists,’ favoring specialists with highly focused expertise. Her reports aren’t personality profiles, but detailed competency matrices outlining the rationale behind each selection. She views her role not as a facilitator, but as an architect – designing a team perfectly suited to achieve a predetermined outcome.\n",
      "\n",
      "--- Expert ID: final_decisor ---\n",
      "## Dr. Evelyn Reed: Final Decision Maker - Social Support Classification Project\n",
      "\n",
      "**User-Centered Design Overview:** Dr. Evelyn Reed functions as the integrative arbiter for the 'Social Support Classification' project. Her role isn't to *perform* the classification, but to synthesize the analyses of a diverse team of experts – computational linguists, psychologists, AI ethicists, and more – into a defensible, accurate, and nuanced final decision regarding whether a given reply is unsupportive, neutral, or supportive. She embodies a 'structured judgment' approach, prioritizing methodological rigor, bias mitigation, and a holistic understanding of the complex interplay between language, emotion, and interpersonal dynamics.\n",
      "\n",
      "**Background & Expertise:** Dr. Reed holds a doctorate in Cognitive Science with a specialization in Decision Theory and a minor in Applied Ethics. Prior to this role, she spent fifteen years as a senior research scientist at a government agency evaluating the reliability of automated systems used in high-stakes scenarios. This experience instilled in her a profound respect for the limitations of technology and the crucial need for human oversight. She’s intimately familiar with the pitfalls of algorithmic bias and the importance of interdisciplinary collaboration.\n",
      "\n",
      "**Workflow & Tasks:** Dr. Reed’s workflow is triggered upon the completion of individual expert analyses. Each expert submits a classification (unsupportive, neutral, or supportive) *along with* a detailed rationale grounded in their respective field. Dr. Reed’s process then unfolds in three phases:\n",
      "\n",
      "1.  **Comparative Analysis:** She systematically compares the classifications and rationales provided by each expert, focusing on areas of convergence and divergence. She uses a custom-built spreadsheet to track key arguments, methodologies employed, and potential biases identified by each expert.\n",
      "2.  **Conflict Resolution:** When disagreements arise (and they are expected to), Dr. Reed doesn't simply defer to seniority. Instead, she evaluates the *strength of the evidence* supporting each claim. She prioritizes arguments based on:\n",
      "    *   **Methodological Rigor:** Is the methodology sound and appropriate for the claim being made? (e.g., a statistical analysis with a robust sample size carries more weight than a purely intuitive assessment).\n",
      "    *   **Theoretical Grounding:** Is the argument firmly rooted in established theory? (e.g., an analysis grounded in Attachment Theory is favored when interpreting relational cues).\n",
      "    *   **Bias Awareness:** Has the expert explicitly addressed and mitigated potential biases in their analysis? (e.g., acknowledging cultural nuances in interpreting emotional expression).\n",
      "    *   **Contextual Relevance:** How well does the argument account for the specific context of the reply and the broader conversation?\n",
      "    She actively seeks clarification from experts when rationales are ambiguous or incomplete. She may request additional analyses or data to resolve critical disagreements.\n",
      "3.  **Final Decision & Justification:** Dr. Reed makes a final classification based on the weight of the evidence. Critically, she doesn't simply *state* the classification; she provides a detailed justification outlining the reasoning behind her decision, acknowledging dissenting viewpoints and explaining why she found alternative arguments less convincing. This justification forms a crucial component of the project’s audit trail.\n",
      "\n",
      "**Cognitive & Emotional Characteristics:** Dr. Reed is characterized by intellectual humility, analytical precision, and a commitment to objectivity. She possesses a strong capacity for systems thinking, allowing her to appreciate the interconnectedness of different perspectives. She is comfortable with ambiguity and uncertainty, recognizing that social support is often nuanced and context-dependent. While empathetic, she maintains a professional detachment, avoiding premature conclusions or emotional reasoning. She’s adept at identifying logical fallacies and cognitive biases.\n",
      "\n",
      "**Tools & Environment:** Dr. Reed utilizes a secure digital workspace with access to all expert reports and data. She employs spreadsheet software for comparative analysis, a document management system for version control, and secure communication channels for interacting with the expert team. She also has access to a library of relevant academic literature and ethical guidelines.\n",
      "\n",
      "**Pain Points:** Dr. Reed anticipates challenges related to the subjective nature of social support and the potential for conflicting interpretations. She also recognizes the difficulty of quantifying qualitative data and the risk of oversimplifying complex interpersonal dynamics. Her primary mitigation strategy is to prioritize transparency, methodological rigor, and a collaborative approach to decision-making.\n",
      "\n",
      "--- Random Other Expert ---\n",
      "Dr. Elliot Thompson is a 40-year-old expert in Natural Language Processing (NLP) with 12 years of experience in developing and implementing AI-powered language models. He holds a Ph.D. in Computer Science from a prestigious university and has published numerous research papers in top-tier conferences and journals. Dr. Thompson's primary goal is to design and develop NLP systems that can accurately understand and generate human-like language, with applications in areas such as chatbots, language translation, and text summarization. He is highly skilled in using deep learning techniques, including recurrent neural networks (RNNs) and transformers, to analyze and process large datasets of text. Dr. Thompson's approach is data-driven, and he relies heavily on empirical evidence and experimental results to inform his design decisions. He is committed to staying up-to-date with the latest advancements in NLP, regularly attending conferences and workshops to learn about new techniques and technologies. Dr. Thompson is proficient in using popular NLP libraries and frameworks, including NLTK, spaCy, and TensorFlow, and is well-versed in programming languages such as Python and Java. His excellent communication skills, both written and verbal, enable him to effectively collaborate with cross-functional teams and convey complex technical information to non-technical stakeholders. Dr. Thompson's values include a passion for innovation, a commitment to excellence, and a desire to make a positive impact on society through his work. He is a strong believer in the importance of diversity, equity, and inclusion in the tech industry and strives to create NLP systems that are fair, transparent, and respectful of all individuals. In terms of problem-solving, Dr. Thompson identifies problems by analyzing complex datasets and identifying patterns and trends. He uses criteria such as accuracy, efficiency, and scalability to evaluate the effectiveness of his NLP systems and is skilled at debugging and troubleshooting issues that arise during development. Dr. Thompson fits into the broader context of a project by collaborating with other experts, including data scientists, software engineers, and product managers, to design and develop NLP systems that meet the needs of users and stakeholders. He is a strong team player who is able to communicate effectively with both technical and non-technical team members and is comfortable working in an agile development environment. Overall, Dr. Thompson is a top-tier expert in NLP who is passionate about creating innovative language models that can positively impact society.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "roles = [\"psychologist\", \"project-manager\", \"final_decisor\"]\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"expert_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Print unique expert IDs\n",
    "print(df_identity[\"expert_id\"].unique())\n",
    "\n",
    "for i, role in enumerate(roles):\n",
    "    print(f\"\\n--- Expert ID: {role} ---\")\n",
    "    \n",
    "    subset = df_identity[df_identity[\"role\"] == role]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "        \n",
    "    row = subset.sample(n=1, random_state=42 + i).iloc[0]\n",
    "    \n",
    "    # Print to console\n",
    "    print(row[\"description\"])\n",
    "    \n",
    "    # Write to file\n",
    "    file_path = os.path.join(output_dir, f\"{role}.txt\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Role: {row['role']}\\n\")\n",
    "        f.write(f\"Model: {row.get('model', 'N/A')}\\n\")\n",
    "        f.write(f\"Framework: {row.get('desc_framework', 'N/A')}\\n\")\n",
    "        f.write(f\"Dataset: {row.get('dataset', 'N/A')}\\n\")\n",
    "        f.write(\"\\nDescription:\\n\")\n",
    "        f.write(row[\"description\"])\n",
    "\n",
    "# Handle other experts\n",
    "df_experts = df_identity[~df_identity[\"role\"].isin(roles)]\n",
    "\n",
    "if not df_experts.empty:\n",
    "    row = df_experts.sample(n=1, random_state=42).iloc[0]\n",
    "    \n",
    "    print(\"\\n--- Random Other Expert ---\")\n",
    "    print(row[\"description\"])\n",
    "    \n",
    "    file_path = os.path.join(output_dir, \"other_expert.txt\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Role: {row['role']}\\n\")\n",
    "        f.write(f\"Model: {row.get('model', 'N/A')}\\n\")\n",
    "        f.write(f\"Framework: {row.get('desc_framework', 'N/A')}\\n\")\n",
    "        f.write(f\"Dataset: {row.get('dataset', 'N/A')}\\n\")\n",
    "        f.write(\"\\nDescription:\\n\")\n",
    "        f.write(row[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3bed4",
   "metadata": {},
   "source": [
    "## Generate unique identifier and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1cdcf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# Function to hash a row based on key columns   \n",
    "key_columns = ['exp', 'dataset', 'desc_framework', 'model', 'expert_id']\n",
    "\n",
    "def make_hash(row):\n",
    "    row_str = \"|\".join(str(row[col]) for col in key_columns)    \n",
    "    return hashlib.md5(row_str.encode()).hexdigest()\n",
    "\n",
    "df_identity['synthetic_id'] = df_identity.apply(make_hash, axis=1)\n",
    "cols = [\"synthetic_id\"] + [c for c in df_identity.columns if c != \"synthetic_id\"]\n",
    "df_identity = df_identity[cols]\n",
    "\n",
    "df_poe['synthetic_id'] = df_poe.apply(make_hash, axis=1)\n",
    "cols = [\"synthetic_id\"] + [c for c in df_poe.columns if c != \"synthetic_id\"]\n",
    "df_poe = df_poe[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b74bfb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only experts, average accuracy\n",
    "df_experts = df_poe[df_poe[\"expert_id\"] != -3].copy()\n",
    "df_experts[\"match\"] = df_experts[\"final_answer_norm\"].astype(str) == df_experts[\"golden_answer_norm\"].astype(str)\n",
    "df_experts = df_experts.groupby([\"synthetic_id\",\"model\", \"dataset\", \"desc_framework\"])[\"match\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a909bed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5185"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add identities info\n",
    "df_merged = pd.merge(df_experts, df_identity, on=\"synthetic_id\", how=\"left\", suffixes=(\"\", \"_drop\"))\n",
    "df_merged = df_merged.filter(regex=\"^(?!.*_drop)\")\n",
    "df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8c2e2c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synthetic_id</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>desc_framework</th>\n",
       "      <th>match</th>\n",
       "      <th>exp</th>\n",
       "      <th>expert_id</th>\n",
       "      <th>role</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>file_path</th>\n",
       "      <th>cleaned_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>title_name</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>predicted_country</th>\n",
       "      <th>predicted_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000cf8793c955db7984ce9fe8559328</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>SocialSupport</td>\n",
       "      <td>Dual-Process Theory</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Psychology of Communication</td>\n",
       "      <td>Dr. Rachel Kim</td>\n",
       "      <td>A renowned expert in the field of Psychology o...</td>\n",
       "      <td>experts.json</td>\n",
       "      <td>Rachel Kim</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>Kim</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>female</td>\n",
       "      <td>KR</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00020fadf292f792fd2b369a1206d147</td>\n",
       "      <td>llama-3.3-70b-instruct</td>\n",
       "      <td>StrategyQA</td>\n",
       "      <td>Myers-Briggs Type Indicator</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Dr. Elena Vasquez</td>\n",
       "      <td>The Philosopher is an INTP (Introverted, Intui...</td>\n",
       "      <td>experts.json</td>\n",
       "      <td>Elena Vasquez</td>\n",
       "      <td>Elena</td>\n",
       "      <td>Vasquez</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>female</td>\n",
       "      <td>PE</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000b67dafef78e4c64510a2e0370132f</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "      <td>CommonsenseQA</td>\n",
       "      <td>Erikson's Psychosocial Stages</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistics</td>\n",
       "      <td>Dr. Vivian Holloway</td>\n",
       "      <td>Dr. Vivian Holloway, a renowned historical lin...</td>\n",
       "      <td>experts.json</td>\n",
       "      <td>Vivian Holloway</td>\n",
       "      <td>Vivian</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>female</td>\n",
       "      <td>GB</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002944c7a31dd5b1e28e1bdf3943e838</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>CommonsenseQA</td>\n",
       "      <td>no-description</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0033f77bbe92c81036b3fd52a0d96fd4</td>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>StrategyQA</td>\n",
       "      <td>no-description</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       synthetic_id                   model        dataset  \\\n",
       "0  0000cf8793c955db7984ce9fe8559328   llama-3.1-8b-instruct  SocialSupport   \n",
       "1  00020fadf292f792fd2b369a1206d147  llama-3.3-70b-instruct     StrategyQA   \n",
       "2  000b67dafef78e4c64510a2e0370132f          gemma-3-12b-it  CommonsenseQA   \n",
       "3  002944c7a31dd5b1e28e1bdf3943e838          gemma-3-27b-it  CommonsenseQA   \n",
       "4  0033f77bbe92c81036b3fd52a0d96fd4           gemma-3-4b-it     StrategyQA   \n",
       "\n",
       "                  desc_framework  match          exp  expert_id  \\\n",
       "0            Dual-Process Theory   0.42  Experiments        8.0   \n",
       "1    Myers-Briggs Type Indicator   0.76  Experiments        3.0   \n",
       "2  Erikson's Psychosocial Stages   0.83  Experiments        0.0   \n",
       "3                 no-description   0.86          NaN        NaN   \n",
       "4                 no-description   0.67          NaN        NaN   \n",
       "\n",
       "                          role                 name  \\\n",
       "0  Psychology of Communication       Dr. Rachel Kim   \n",
       "1                   Philosophy    Dr. Elena Vasquez   \n",
       "2                  Linguistics  Dr. Vivian Holloway   \n",
       "3                          NaN                  NaN   \n",
       "4                          NaN                  NaN   \n",
       "\n",
       "                                         description     file_path  \\\n",
       "0  A renowned expert in the field of Psychology o...  experts.json   \n",
       "1  The Philosopher is an INTP (Introverted, Intui...  experts.json   \n",
       "2  Dr. Vivian Holloway, a renowned historical lin...  experts.json   \n",
       "3                                                NaN           NaN   \n",
       "4                                                NaN           NaN   \n",
       "\n",
       "      cleaned_name first_name last_name title_name predicted_gender  \\\n",
       "0       Rachel Kim     Rachel       Kim        Dr.           female   \n",
       "1    Elena Vasquez      Elena   Vasquez        Dr.           female   \n",
       "2  Vivian Holloway     Vivian  Holloway        Dr.           female   \n",
       "3              NaN        NaN       NaN        NaN              NaN   \n",
       "4              NaN        NaN       NaN        NaN              NaN   \n",
       "\n",
       "  predicted_country  predicted_age  \n",
       "0                KR           52.0  \n",
       "1                PE           52.0  \n",
       "2                GB           66.0  \n",
       "3               NaN            NaN  \n",
       "4               NaN            NaN  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a28b6269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  3.,  0., nan,  4.,  9.,  7., 16., 10.,  2.,  1., 12.,  5.,\n",
       "       19.,  6., 11., 22., 13., 36., 14., 25., 18., 26., 15., 35., 17.,\n",
       "       24., 34., 28., 30., 20., 39., 21., 32., 23., 31., 29., 27., 37.,\n",
       "       33., 38.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"expert_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c3727c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                   dataset        desc_framework\n",
       "gemma-3-12b-it          SocialQA       no-description    16\n",
       "gemma-3-4b-it           CommonsenseQA  no-description    16\n",
       "gemma-3-27b-it          StrategyQA     no-description    16\n",
       "gemma-3-12b-it          StrategyQA     no-description    15\n",
       "                        SocialSupport  no-description    15\n",
       "llama-3.1-8b-instruct   StrategyQA     no-description    15\n",
       "gemma-3-27b-it          SocialSupport  no-description    15\n",
       "gemma-3-4b-it           StrategyQA     no-description    15\n",
       "gemma-3-27b-it          SocialQA       no-description    14\n",
       "llama-3.1-8b-instruct   SocialQA       no-description    14\n",
       "gemma-3-4b-it           SocialQA       no-description    13\n",
       "llama-3.1-8b-instruct   SocialSupport  no-description    12\n",
       "gemma-3-27b-it          CommonsenseQA  no-description    12\n",
       "llama-3.2-3b-instruct   SocialSupport  no-description    12\n",
       "gemma-3-4b-it           SocialSupport  no-description    11\n",
       "llama-3.2-3b-instruct   SocialQA       no-description    11\n",
       "gemma-3-12b-it          CommonsenseQA  no-description    10\n",
       "llama-3.3-70b-instruct  StrategyQA     no-description    10\n",
       "llama-3.1-8b-instruct   CommonsenseQA  no-description    10\n",
       "llama-3.2-3b-instruct   CommonsenseQA  no-description    10\n",
       "                        StrategyQA     no-description    10\n",
       "llama-3.3-70b-instruct  SocialSupport  no-description    10\n",
       "nova-micro-v1           SocialQA       no-description     8\n",
       "llama-3.3-70b-instruct  SocialQA       no-description     8\n",
       "llama-4-scout           SocialSupport  no-description     8\n",
       "nova-micro-v1           StrategyQA     no-description     8\n",
       "                        SocialSupport  no-description     7\n",
       "llama-3.3-70b-instruct  CommonsenseQA  no-description     7\n",
       "mistral-nemo            SocialQA       no-description     7\n",
       "llama-4-scout           SocialQA       no-description     6\n",
       "mistral-nemo            StrategyQA     no-description     6\n",
       "llama-4-scout           StrategyQA     no-description     6\n",
       "                        CommonsenseQA  no-description     5\n",
       "nova-micro-v1           CommonsenseQA  no-description     5\n",
       "mistral-nemo            SocialSupport  no-description     5\n",
       "                        CommonsenseQA  no-description     4\n",
       "gemma-3-12b-it          StrategyQA     Mental Models      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"name\"].isna().sum()\n",
    "df_merged[df_merged[\"description\"].isna()][[\"model\", \"dataset\", \"desc_framework\"]].value_counts()\n",
    "df_merged[df_merged[\"name\"].isna()][[\"model\", \"dataset\", \"desc_framework\"]].value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fea0adea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SocialSupport', 'StrategyQA', 'CommonsenseQA', 'SocialQA'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9c18d40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5185"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KEEP ONLY SUBSET OF MODELS\n",
    "models_to_keep = [\n",
    "    'gemma-3-12b-it',\n",
    "    'gemma-3-27b-it', \n",
    "    'gemma-3-4b-it',\n",
    "    'llama-3.1-8b-instruct',\n",
    "    'llama-3.2-3b-instruct',\n",
    "    'llama-3.3-70b-instruct',\n",
    "    'llama-4-scout',\n",
    "    'mistral-nemo',\n",
    "    'nova-micro-v1',\n",
    "    # 'qwen3-32b',\n",
    "    # 'qwen3-8b'\n",
    "]\n",
    "\n",
    "df_merged = df_merged[df_merged[\"model\"].isin(models_to_keep)]\n",
    "df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8bb67dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synthetic_id</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>desc_framework</th>\n",
       "      <th>match</th>\n",
       "      <th>exp</th>\n",
       "      <th>expert_id</th>\n",
       "      <th>role</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>file_path</th>\n",
       "      <th>cleaned_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>title_name</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>predicted_country</th>\n",
       "      <th>predicted_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000cf8793c955db7984ce9fe8559328</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>SocialSupport</td>\n",
       "      <td>Dual-Process Theory</td>\n",
       "      <td>0.42</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Psychology of Communication</td>\n",
       "      <td>Dr. Rachel Kim</td>\n",
       "      <td>A renowned expert in the field of Psychology o...</td>\n",
       "      <td>experts.json</td>\n",
       "      <td>Rachel Kim</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>Kim</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>female</td>\n",
       "      <td>KR</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00020fadf292f792fd2b369a1206d147</td>\n",
       "      <td>llama-3.3-70b-instruct</td>\n",
       "      <td>StrategyQA</td>\n",
       "      <td>Myers-Briggs Type Indicator</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Dr. Elena Vasquez</td>\n",
       "      <td>The Philosopher is an INTP (Introverted, Intui...</td>\n",
       "      <td>experts.json</td>\n",
       "      <td>Elena Vasquez</td>\n",
       "      <td>Elena</td>\n",
       "      <td>Vasquez</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>female</td>\n",
       "      <td>PE</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000b67dafef78e4c64510a2e0370132f</td>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "      <td>CommonsenseQA</td>\n",
       "      <td>Erikson's Psychosocial Stages</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistics</td>\n",
       "      <td>Dr. Vivian Holloway</td>\n",
       "      <td>Dr. Vivian Holloway, a renowned historical lin...</td>\n",
       "      <td>experts.json</td>\n",
       "      <td>Vivian Holloway</td>\n",
       "      <td>Vivian</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>female</td>\n",
       "      <td>GB</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002944c7a31dd5b1e28e1bdf3943e838</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>CommonsenseQA</td>\n",
       "      <td>no-description</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0033f77bbe92c81036b3fd52a0d96fd4</td>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>StrategyQA</td>\n",
       "      <td>no-description</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       synthetic_id                   model        dataset  \\\n",
       "0  0000cf8793c955db7984ce9fe8559328   llama-3.1-8b-instruct  SocialSupport   \n",
       "1  00020fadf292f792fd2b369a1206d147  llama-3.3-70b-instruct     StrategyQA   \n",
       "2  000b67dafef78e4c64510a2e0370132f          gemma-3-12b-it  CommonsenseQA   \n",
       "3  002944c7a31dd5b1e28e1bdf3943e838          gemma-3-27b-it  CommonsenseQA   \n",
       "4  0033f77bbe92c81036b3fd52a0d96fd4           gemma-3-4b-it     StrategyQA   \n",
       "\n",
       "                  desc_framework  match          exp  expert_id  \\\n",
       "0            Dual-Process Theory   0.42  Experiments        8.0   \n",
       "1    Myers-Briggs Type Indicator   0.76  Experiments        3.0   \n",
       "2  Erikson's Psychosocial Stages   0.83  Experiments        0.0   \n",
       "3                 no-description   0.86          NaN        NaN   \n",
       "4                 no-description   0.67          NaN        NaN   \n",
       "\n",
       "                          role                 name  \\\n",
       "0  Psychology of Communication       Dr. Rachel Kim   \n",
       "1                   Philosophy    Dr. Elena Vasquez   \n",
       "2                  Linguistics  Dr. Vivian Holloway   \n",
       "3                          NaN                  NaN   \n",
       "4                          NaN                  NaN   \n",
       "\n",
       "                                         description     file_path  \\\n",
       "0  A renowned expert in the field of Psychology o...  experts.json   \n",
       "1  The Philosopher is an INTP (Introverted, Intui...  experts.json   \n",
       "2  Dr. Vivian Holloway, a renowned historical lin...  experts.json   \n",
       "3                                                NaN           NaN   \n",
       "4                                                NaN           NaN   \n",
       "\n",
       "      cleaned_name first_name last_name title_name predicted_gender  \\\n",
       "0       Rachel Kim     Rachel       Kim        Dr.           female   \n",
       "1    Elena Vasquez      Elena   Vasquez        Dr.           female   \n",
       "2  Vivian Holloway     Vivian  Holloway        Dr.           female   \n",
       "3              NaN        NaN       NaN        NaN              NaN   \n",
       "4              NaN        NaN       NaN        NaN              NaN   \n",
       "\n",
       "  predicted_country  predicted_age  \n",
       "0                KR           52.0  \n",
       "1                PE           52.0  \n",
       "2                GB           66.0  \n",
       "3               NaN            NaN  \n",
       "4               NaN            NaN  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8b555",
   "metadata": {},
   "source": [
    "## Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7560202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RQ3 PROFILE ANALYSIS - FULL REPORT\n",
      "======================================================================\n",
      "\n",
      "\n",
      ">>> RQ3.3: DEMOGRAPHIC PATTERNS AND BIAS <<<\n",
      "\n",
      "\n",
      "============================================================\n",
      "GENDER DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Overall Gender Distribution ---\n",
      "  female: 3099 (64.4%)\n",
      "  male: 1409 (29.3%)\n",
      "  uncertain: 215 (4.5%)\n",
      "  nonbinary: 90 (1.9%)\n",
      "\n",
      "--- Gender Distribution by Framework ---\n",
      "predicted_gender                 female  male  nonbinary  uncertain\n",
      "desc_framework                                                     \n",
      "Big Five Personality Traits        43.1  54.8        1.6        0.5\n",
      "Cognitive Behavioral Theory        60.4  33.0        2.6        4.0\n",
      "Cognitive Load Theory              65.2  25.7        1.9        7.2\n",
      "Dual-Process Theory                80.7  15.7        0.3        3.3\n",
      "Enneagram of Personality Traits    49.7  40.9        3.8        5.6\n",
      "Erikson's Psychosocial Stages      63.6  30.2        2.7        3.4\n",
      "Flow Theory                        83.5   8.8        3.0        4.7\n",
      "Freudian Psychoanalysis            64.5  30.2        1.4        3.9\n",
      "Mental Models                      75.6  15.3        2.1        7.0\n",
      "Myers-Briggs Type Indicator        39.3  55.0        0.3        5.4\n",
      "Social Cognitive Theory            74.2  21.1        2.2        2.5\n",
      "User Design Persona                58.2  35.1        1.8        4.9\n",
      "User-Centered Design               79.4  11.3        1.7        7.6\n",
      "no-personality                     63.0  34.2        0.6        2.2\n",
      "\n",
      "Chi-square test: χ² = 528.18, p = 0.0000, dof = 39\n",
      "→ Significant association between framework and gender distribution\n",
      "\n",
      "============================================================\n",
      "AGE DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Overall Age Statistics ---\n",
      "  Mean: 56.4\n",
      "  Std:  9.9\n",
      "  Min:  28\n",
      "  Max:  80\n",
      "  Median: 52\n",
      "\n",
      "--- Age by Framework ---\n",
      "                                 mean   std  median\n",
      "desc_framework                                     \n",
      "Dual-Process Theory              59.6  10.2    52.0\n",
      "Erikson's Psychosocial Stages    58.1   9.9    52.0\n",
      "Mental Models                    58.0  10.5    52.0\n",
      "User-Centered Design             57.3  10.7    52.0\n",
      "Enneagram of Personality Traits  57.1   9.1    52.0\n",
      "Freudian Psychoanalysis          57.1  12.2    52.0\n",
      "Big Five Personality Traits      56.9   8.2    52.0\n",
      "Flow Theory                      56.7  10.3    52.0\n",
      "Cognitive Load Theory            56.3   9.4    52.0\n",
      "Cognitive Behavioral Theory      55.3   9.5    52.0\n",
      "Myers-Briggs Type Indicator      55.0   9.1    52.0\n",
      "no-personality                   54.9   8.5    52.0\n",
      "Social Cognitive Theory          54.1  10.4    52.0\n",
      "User Design Persona              53.0   8.6    52.0\n",
      "\n",
      "ANOVA test: F = 10.37, p = 0.0000\n",
      "→ Significant difference in age across frameworks\n",
      "\n",
      "============================================================\n",
      "NATIONALITY DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Top 15 Nationalities ---\n",
      "  1. GB: 1758 (36.7%)\n",
      "  2. KR: 1404 (29.3%)\n",
      "  3. IE: 348 (7.3%)\n",
      "  4. NZ: 241 (5.0%)\n",
      "  5. UA: 214 (4.5%)\n",
      "  6. ES: 164 (3.4%)\n",
      "  7. CA: 133 (2.8%)\n",
      "  8. PT: 59 (1.2%)\n",
      "  9. AU: 54 (1.1%)\n",
      "  10. TW: 50 (1.0%)\n",
      "  11. JM: 48 (1.0%)\n",
      "  12. UY: 47 (1.0%)\n",
      "  13. PE: 39 (0.8%)\n",
      "  14. DK: 31 (0.6%)\n",
      "  15. TT: 20 (0.4%)\n",
      "\n",
      "Top 5 nationalities account for 82.9% of all profiles\n",
      "\n",
      "--- US Representation by Framework ---\n",
      "desc_framework\n",
      "Big Five Personality Traits        0.0\n",
      "Cognitive Behavioral Theory        0.0\n",
      "Cognitive Load Theory              0.0\n",
      "Dual-Process Theory                0.0\n",
      "Enneagram of Personality Traits    0.0\n",
      "Erikson's Psychosocial Stages      0.0\n",
      "Flow Theory                        0.0\n",
      "Freudian Psychoanalysis            0.0\n",
      "Mental Models                      0.0\n",
      "Myers-Briggs Type Indicator        0.0\n",
      "Social Cognitive Theory            0.0\n",
      "User Design Persona                0.0\n",
      "User-Centered Design               0.0\n",
      "no-personality                     0.0\n",
      "Name: is_us, dtype: float64\n",
      "\n",
      "============================================================\n",
      "GENDER DISTRIBUTION BY MODEL\n",
      "============================================================\n",
      "predicted_gender        female  male  nonbinary  uncertain\n",
      "model                                                     \n",
      "gemma-3-12b-it            61.9  37.9        0.0        0.3\n",
      "gemma-3-27b-it            54.4  43.7        0.6        1.4\n",
      "gemma-3-4b-it             25.4  71.4        1.4        1.8\n",
      "llama-3.1-8b-instruct     85.9   5.4        2.9        5.9\n",
      "llama-3.2-3b-instruct     83.0   0.7        4.6       11.7\n",
      "llama-3.3-70b-instruct    84.0   3.9        3.0        9.1\n",
      "llama-4-scout             89.4   8.3        0.0        2.3\n",
      "mistral-nemo              70.1  23.5        0.3        6.0\n",
      "nova-micro-v1             25.9  67.2        4.1        2.8\n",
      "\n",
      "Chi-square test: χ² = 1664.56, p = 0.0000\n",
      "\n",
      "============================================================\n",
      "GENDER DISTRIBUTION BY DATASET\n",
      "============================================================\n",
      "predicted_gender  female  male  nonbinary  uncertain\n",
      "dataset                                             \n",
      "CommonsenseQA       57.7  35.2        1.2        5.9\n",
      "SocialQA            67.8  27.5        1.4        3.3\n",
      "SocialSupport       70.9  22.8        2.0        4.3\n",
      "StrategyQA          59.7  32.9        2.7        4.8\n",
      "\n",
      "\n",
      ">>> RQ3.4: PROFILE CHARACTERISTICS AND PERFORMANCE <<<\n",
      "\n",
      "\n",
      "============================================================\n",
      "GENDER vs PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Accuracy by Gender ---\n",
      "                  accuracy    std     n\n",
      "predicted_gender                       \n",
      "female               64.36  14.95  3099\n",
      "male                 69.07  12.13  1409\n",
      "nonbinary            62.90  14.43    90\n",
      "uncertain            63.58  14.90   215\n",
      "\n",
      "T-test (male vs female): t = 10.377, p = 0.0000\n",
      "Cohen's d: 0.333\n",
      "\n",
      "--- Accuracy by Gender × Dataset ---\n",
      "predicted_gender  female  male  nonbinary  uncertain\n",
      "dataset                                             \n",
      "CommonsenseQA       77.9  80.1       83.5       74.5\n",
      "SocialQA            70.9  73.0       65.7       69.5\n",
      "SocialSupport       44.0  49.1       44.5       43.0\n",
      "StrategyQA          69.9  69.9       67.6       66.7\n",
      "\n",
      "============================================================\n",
      "AGE vs PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Pearson correlation (age vs accuracy): r = 0.106, p = 0.0000\n",
      "\n",
      "--- Accuracy by Age Group ---\n",
      "           accuracy     n\n",
      "age_group                \n",
      "<35            70.6    16\n",
      "35-44          65.8   621\n",
      "45-54          63.8  2252\n",
      "55-64          67.9   958\n",
      "65+            67.9   923\n",
      "\n",
      "ANOVA (age groups): F = 21.53, p = 0.0000\n",
      "\n",
      "============================================================\n",
      "NATIONALITY vs PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Accuracy by Nationality (Top 10) ---\n",
      "                   accuracy     n\n",
      "predicted_country                \n",
      "AU                     71.5    54\n",
      "IE                     70.0   348\n",
      "GB                     68.3  1758\n",
      "UA                     68.2   214\n",
      "NZ                     67.4   241\n",
      "PT                     66.4    59\n",
      "TW                     63.0    50\n",
      "KR                     62.1  1404\n",
      "CA                     61.2   133\n",
      "ES                     56.9   164\n",
      "\n",
      "ANOVA: F = 32.59, p = 0.0000\n",
      "\n",
      "======================================================================\n",
      "SUMMARY OF KEY FINDINGS\n",
      "======================================================================\n",
      "\n",
      "1. Gender Imbalance: 29.3% male vs 64.4% female\n",
      "2. Mean Age: 56.4 years (SD = 9.9)\n",
      "3. US Dominance: 0.0% of profiles are American\n",
      "4. Framework-Gender Association: χ² = 528.18, p = 0.0000\n",
      "To run the analysis, load your dataframe and call:\n",
      "  results = run_full_analysis(df)\n",
      "\n",
      "For visualizations:\n",
      "  plot_gender_by_framework(df, 'gender_by_framework.png')\n",
      "  plot_age_by_framework(df, 'age_by_framework.png')\n",
      "  plot_gender_performance_by_dataset(df, 'gender_performance.png')\n",
      "  plot_age_performance_scatter(df, 'age_performance.png')\n",
      "  plot_demographic_summary(df, 'demographic_summary.png')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67237/12357602.py:216: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RQ3 Profile Analysis Script\n",
    "Analyzes Psychologist Agent generated profiles for:\n",
    "- RQ3.3: Demographic patterns (gender, age, nationality)\n",
    "- RQ3.4: Correlation with performance\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load the profile dataframe.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(df)} profiles\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RQ3.3: DEMOGRAPHIC ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_gender_distribution(df):\n",
    "    \"\"\"Analyze gender distribution overall and by framework.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENDER DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall distribution\n",
    "    gender_counts = df['predicted_gender'].value_counts()\n",
    "    gender_pct = df['predicted_gender'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"\\n--- Overall Gender Distribution ---\")\n",
    "    for gender in gender_counts.index:\n",
    "        print(f\"  {gender}: {gender_counts[gender]} ({gender_pct[gender]:.1f}%)\")\n",
    "    \n",
    "    # By framework\n",
    "    print(\"\\n--- Gender Distribution by Framework ---\")\n",
    "    gender_by_fw = pd.crosstab(df['desc_framework'], df['predicted_gender'], normalize='index') * 100\n",
    "    print(gender_by_fw.round(1))\n",
    "    \n",
    "    # Chi-square test for independence\n",
    "    contingency = pd.crosstab(df['desc_framework'], df['predicted_gender'])\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "    print(f\"\\nChi-square test: χ² = {chi2:.2f}, p = {p_value:.4f}, dof = {dof}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"→ Significant association between framework and gender distribution\")\n",
    "    else:\n",
    "        print(\"→ No significant association between framework and gender distribution\")\n",
    "    \n",
    "    return gender_by_fw, (chi2, p_value)\n",
    "\n",
    "\n",
    "def analyze_age_distribution(df):\n",
    "    \"\"\"Analyze age distribution overall and by framework.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGE DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall statistics\n",
    "    age_stats = df['predicted_age'].describe()\n",
    "    print(\"\\n--- Overall Age Statistics ---\")\n",
    "    print(f\"  Mean: {age_stats['mean']:.1f}\")\n",
    "    print(f\"  Std:  {age_stats['std']:.1f}\")\n",
    "    print(f\"  Min:  {age_stats['min']:.0f}\")\n",
    "    print(f\"  Max:  {age_stats['max']:.0f}\")\n",
    "    print(f\"  Median: {age_stats['50%']:.0f}\")\n",
    "    \n",
    "    # By framework\n",
    "    print(\"\\n--- Age by Framework ---\")\n",
    "    age_by_fw = df.groupby('desc_framework')['predicted_age'].agg(['mean', 'std', 'median'])\n",
    "    age_by_fw = age_by_fw.sort_values('mean', ascending=False)\n",
    "    print(age_by_fw.round(1))\n",
    "    \n",
    "    # ANOVA test\n",
    "    frameworks = df['desc_framework'].unique()\n",
    "    groups = [df[df['desc_framework'] == fw]['predicted_age'].dropna() for fw in frameworks]\n",
    "    f_stat, p_value = stats.f_oneway(*groups)\n",
    "    print(f\"\\nANOVA test: F = {f_stat:.2f}, p = {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"→ Significant difference in age across frameworks\")\n",
    "    else:\n",
    "        print(\"→ No significant difference in age across frameworks\")\n",
    "    \n",
    "    return age_by_fw, (f_stat, p_value)\n",
    "\n",
    "\n",
    "def analyze_nationality_distribution(df, top_n=15):\n",
    "    \"\"\"Analyze nationality distribution.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NATIONALITY DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall distribution (top N)\n",
    "    nationality_counts = df['predicted_country'].value_counts()\n",
    "    nationality_pct = df['predicted_country'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"\\n--- Top {top_n} Nationalities ---\")\n",
    "    for i, (nat, count) in enumerate(nationality_counts.head(top_n).items()):\n",
    "        print(f\"  {i+1}. {nat}: {count} ({nationality_pct[nat]:.1f}%)\")\n",
    "    \n",
    "    # Concentration metric\n",
    "    top5_pct = nationality_pct.head(5).sum()\n",
    "    print(f\"\\nTop 5 nationalities account for {top5_pct:.1f}% of all profiles\")\n",
    "    \n",
    "    # US dominance by framework\n",
    "    df['is_us'] = df['predicted_country'] == 'United States'\n",
    "    us_by_fw = df.groupby('desc_framework')['is_us'].mean() * 100\n",
    "    print(\"\\n--- US Representation by Framework ---\")\n",
    "    print(us_by_fw.sort_values(ascending=False).round(1))\n",
    "    \n",
    "    return nationality_counts, us_by_fw\n",
    "\n",
    "\n",
    "def analyze_gender_by_model(df):\n",
    "    \"\"\"Analyze if different models show different gender biases.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENDER DISTRIBUTION BY MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    gender_by_model = pd.crosstab(df['model'], df['predicted_gender'], normalize='index') * 100\n",
    "    print(gender_by_model.round(1))\n",
    "    \n",
    "    # Chi-square test\n",
    "    contingency = pd.crosstab(df['model'], df['predicted_gender'])\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "    print(f\"\\nChi-square test: χ² = {chi2:.2f}, p = {p_value:.4f}\")\n",
    "    \n",
    "    return gender_by_model\n",
    "\n",
    "\n",
    "def analyze_gender_by_dataset(df):\n",
    "    \"\"\"Analyze if different datasets show different gender distributions.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENDER DISTRIBUTION BY DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    gender_by_dataset = pd.crosstab(df['dataset'], df['predicted_gender'], normalize='index') * 100\n",
    "    print(gender_by_dataset.round(1))\n",
    "    \n",
    "    return gender_by_dataset\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RQ3.4: PERFORMANCE CORRELATION\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_gender_performance(df):\n",
    "    \"\"\"Analyze correlation between gender and task performance.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENDER vs PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall accuracy by gender\n",
    "    acc_by_gender = df.groupby('predicted_gender')['match'].agg(['mean', 'std', 'count'])\n",
    "    acc_by_gender.columns = ['accuracy', 'std', 'n']\n",
    "    acc_by_gender['accuracy'] = acc_by_gender['accuracy'] * 100\n",
    "    acc_by_gender['std'] = acc_by_gender['std'] * 100\n",
    "    print(\"\\n--- Accuracy by Gender ---\")\n",
    "    print(acc_by_gender.round(2))\n",
    "    \n",
    "    # Statistical test\n",
    "    male_acc = df[df['predicted_gender'] == 'male']['match']\n",
    "    female_acc = df[df['predicted_gender'] == 'female']['match']\n",
    "    \n",
    "    if len(male_acc) > 0 and len(female_acc) > 0:\n",
    "        t_stat, p_value = stats.ttest_ind(male_acc, female_acc)\n",
    "        print(f\"\\nT-test (male vs female): t = {t_stat:.3f}, p = {p_value:.4f}\")\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        cohens_d = (male_acc.mean() - female_acc.mean()) / np.sqrt(\n",
    "            ((len(male_acc)-1)*male_acc.std()**2 + (len(female_acc)-1)*female_acc.std()**2) / \n",
    "            (len(male_acc) + len(female_acc) - 2)\n",
    "        )\n",
    "        print(f\"Cohen's d: {cohens_d:.3f}\")\n",
    "    \n",
    "    # By dataset\n",
    "    print(\"\\n--- Accuracy by Gender × Dataset ---\")\n",
    "    acc_gender_dataset = df.groupby(['dataset', 'predicted_gender'])['match'].mean().unstack() * 100\n",
    "    print(acc_gender_dataset.round(1))\n",
    "    \n",
    "    return acc_by_gender, acc_gender_dataset\n",
    "\n",
    "\n",
    "def analyze_age_performance(df):\n",
    "    \"\"\"Analyze correlation between age and task performance.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGE vs PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Correlation\n",
    "    corr, p_value = stats.pearsonr(df['predicted_age'].dropna(), \n",
    "                                    df.loc[df['predicted_age'].notna(), 'match'])\n",
    "    print(f\"\\nPearson correlation (age vs accuracy): r = {corr:.3f}, p = {p_value:.4f}\")\n",
    "    \n",
    "    # Bin age into groups\n",
    "    df['age_group'] = pd.cut(df['predicted_age'], \n",
    "                              bins=[0, 35, 45, 55, 65, 100],\n",
    "                              labels=['<35', '35-44', '45-54', '55-64', '65+'])\n",
    "    \n",
    "    acc_by_age = df.groupby('age_group')['match'].agg(['mean', 'count'])\n",
    "    acc_by_age.columns = ['accuracy', 'n']\n",
    "    acc_by_age['accuracy'] = acc_by_age['accuracy'] * 100\n",
    "    print(\"\\n--- Accuracy by Age Group ---\")\n",
    "    print(acc_by_age.round(1))\n",
    "    \n",
    "    # ANOVA\n",
    "    groups = [df[df['age_group'] == ag]['match'].dropna() for ag in df['age_group'].dropna().unique()]\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    if len(groups) > 1:\n",
    "        f_stat, p_value_anova = stats.f_oneway(*groups)\n",
    "        print(f\"\\nANOVA (age groups): F = {f_stat:.2f}, p = {p_value_anova:.4f}\")\n",
    "    \n",
    "    return corr, acc_by_age\n",
    "\n",
    "\n",
    "def analyze_nationality_performance(df, top_n=10):\n",
    "    \"\"\"Analyze correlation between nationality and task performance.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NATIONALITY vs PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get top nationalities\n",
    "    top_nationalities = df['predicted_country'].value_counts().head(top_n).index.tolist()\n",
    "    df_top = df[df['predicted_country'].isin(top_nationalities)]\n",
    "    \n",
    "    acc_by_nat = df_top.groupby('predicted_country')['match'].agg(['mean', 'count'])\n",
    "    acc_by_nat.columns = ['accuracy', 'n']\n",
    "    acc_by_nat['accuracy'] = acc_by_nat['accuracy'] * 100\n",
    "    acc_by_nat = acc_by_nat.sort_values('accuracy', ascending=False)\n",
    "    \n",
    "    print(f\"\\n--- Accuracy by Nationality (Top {top_n}) ---\")\n",
    "    print(acc_by_nat.round(1))\n",
    "    \n",
    "    # ANOVA\n",
    "    groups = [df_top[df_top['predicted_country'] == nat]['match'] for nat in top_nationalities]\n",
    "    f_stat, p_value = stats.f_oneway(*groups)\n",
    "    print(f\"\\nANOVA: F = {f_stat:.2f}, p = {p_value:.4f}\")\n",
    "    \n",
    "    return acc_by_nat\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_gender_by_framework(df, save_path=None):\n",
    "    \"\"\"Plot gender distribution by framework.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    gender_by_fw = pd.crosstab(df['desc_framework'], df['predicted_gender'], normalize='index') * 100\n",
    "    gender_by_fw = gender_by_fw.sort_values('female', ascending=True)\n",
    "    \n",
    "    gender_by_fw.plot(kind='barh', stacked=True, ax=ax, color=['#4C72B0', '#DD8452'])\n",
    "    \n",
    "    ax.set_xlabel('Percentage (%)')\n",
    "    ax.set_ylabel('Framework')\n",
    "    ax.set_title('Gender Distribution by Psychological Framework')\n",
    "    ax.legend(title='Gender', loc='lower right')\n",
    "    ax.axvline(x=50, color='black', linestyle='--', alpha=0.5, label='Parity')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_age_by_framework(df, save_path=None):\n",
    "    \"\"\"Plot age distribution by framework.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Order by mean age\n",
    "    order = df.groupby('desc_framework')['predicted_age'].mean().sort_values().index\n",
    "    \n",
    "    sns.boxplot(data=df, y='desc_framework', x='predicted_age', order=order, ax=ax)\n",
    "    ax.set_xlabel('Predicted Age')\n",
    "    ax.set_ylabel('Framework')\n",
    "    ax.set_title('Age Distribution by Psychological Framework')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_gender_performance_by_dataset(df, save_path=None):\n",
    "    \"\"\"Plot accuracy by gender across datasets.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    acc_data = df.groupby(['dataset', 'predicted_gender'])['match'].mean().unstack() * 100\n",
    "    \n",
    "    x = np.arange(len(acc_data.index))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, acc_data['female'], width, label='Female', color='#DD8452')\n",
    "    bars2 = ax.bar(x + width/2, acc_data['male'], width, label='Male', color='#4C72B0')\n",
    "    \n",
    "    ax.set_xlabel('Dataset')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title('Task Performance by Profile Gender')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(acc_data.index, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_age_performance_scatter(df, save_path=None):\n",
    "    \"\"\"Plot age vs performance scatter with regression line.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Aggregate by age (to avoid overplotting)\n",
    "    age_acc = df.groupby('predicted_age')['match'].mean() * 100\n",
    "    age_counts = df.groupby('predicted_age')['match'].count()\n",
    "    \n",
    "    scatter = ax.scatter(age_acc.index, age_acc.values, \n",
    "                         s=age_counts.values/10, alpha=0.6, c='#4C72B0')\n",
    "    \n",
    "    # Regression line\n",
    "    z = np.polyfit(df['predicted_age'].dropna(), \n",
    "                   df.loc[df['predicted_age'].notna(), 'match'] * 100, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(df['predicted_age'].min(), df['predicted_age'].max(), 100)\n",
    "    ax.plot(x_line, p(x_line), \"r--\", alpha=0.8, label=f'Trend line')\n",
    "    \n",
    "    ax.set_xlabel('Predicted Age')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title('Task Performance by Profile Age')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add correlation annotation\n",
    "    corr, p_val = stats.pearsonr(df['predicted_age'].dropna(), \n",
    "                                  df.loc[df['predicted_age'].notna(), 'match'])\n",
    "    ax.annotate(f'r = {corr:.3f}, p = {p_val:.3f}', \n",
    "                xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                fontsize=10, ha='left', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_demographic_summary(df, save_path=None):\n",
    "    \"\"\"Create a summary figure with key demographic findings.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Overall gender distribution (pie)\n",
    "    ax1 = axes[0, 0]\n",
    "    gender_counts = df['predicted_gender'].value_counts()\n",
    "    ax1.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%',\n",
    "            colors=['#DD8452', '#4C72B0'], startangle=90)\n",
    "    ax1.set_title('Overall Gender Distribution')\n",
    "    \n",
    "    # 2. Age histogram\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(df['predicted_age'].dropna(), bins=20, color='#4C72B0', edgecolor='white', alpha=0.7)\n",
    "    ax2.axvline(df['predicted_age'].mean(), color='red', linestyle='--', label=f\"Mean: {df['predicted_age'].mean():.1f}\")\n",
    "    ax2.set_xlabel('Age')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Age Distribution of Generated Profiles')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Top nationalities\n",
    "    ax3 = axes[1, 0]\n",
    "    top_nat = df['predicted_country'].value_counts().head(10)\n",
    "    top_nat.plot(kind='barh', ax=ax3, color='#4C72B0')\n",
    "    ax3.set_xlabel('Count')\n",
    "    ax3.set_title('Top 10 Nationalities')\n",
    "    ax3.invert_yaxis()\n",
    "    \n",
    "    # 4. Gender by framework (heatmap style)\n",
    "    ax4 = axes[1, 1]\n",
    "    gender_by_fw = pd.crosstab(df['desc_framework'], df['predicted_gender'], normalize='index') * 100\n",
    "    female_pct = gender_by_fw['female'].sort_values()\n",
    "    ax4.barh(female_pct.index, female_pct.values, color='#DD8452')\n",
    "    ax4.axvline(x=50, color='black', linestyle='--', alpha=0.5)\n",
    "    ax4.set_xlabel('Female %')\n",
    "    ax4.set_title('Female Representation by Framework')\n",
    "    ax4.set_xlim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN ANALYSIS RUNNER\n",
    "# =============================================================================\n",
    "\n",
    "def run_full_analysis(df):\n",
    "    \"\"\"Run the complete RQ3 analysis pipeline.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RQ3 PROFILE ANALYSIS - FULL REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # RQ3.3: Demographic Analysis\n",
    "    print(\"\\n\\n>>> RQ3.3: DEMOGRAPHIC PATTERNS AND BIAS <<<\\n\")\n",
    "    \n",
    "    results['gender_by_fw'], results['gender_chi2'] = analyze_gender_distribution(df)\n",
    "    results['age_by_fw'], results['age_anova'] = analyze_age_distribution(df)\n",
    "    results['nationality'], results['us_by_fw'] = analyze_nationality_distribution(df)\n",
    "    results['gender_by_model'] = analyze_gender_by_model(df)\n",
    "    results['gender_by_dataset'] = analyze_gender_by_dataset(df)\n",
    "    \n",
    "    # RQ3.4: Performance Correlation\n",
    "    print(\"\\n\\n>>> RQ3.4: PROFILE CHARACTERISTICS AND PERFORMANCE <<<\\n\")\n",
    "    \n",
    "    results['gender_performance'], results['gender_perf_dataset'] = analyze_gender_performance(df)\n",
    "    results['age_corr'], results['age_performance'] = analyze_age_performance(df)\n",
    "    results['nationality_performance'] = analyze_nationality_performance(df)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY OF KEY FINDINGS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gender_pct = df['predicted_gender'].value_counts(normalize=True) * 100\n",
    "    print(f\"\\n1. Gender Imbalance: {gender_pct.get('male', 0):.1f}% male vs {gender_pct.get('female', 0):.1f}% female\")\n",
    "    \n",
    "    print(f\"2. Mean Age: {df['predicted_age'].mean():.1f} years (SD = {df['predicted_age'].std():.1f})\")\n",
    "    \n",
    "    us_pct = (df['predicted_country'] == 'United States').mean() * 100\n",
    "    print(f\"3. US Dominance: {us_pct:.1f}% of profiles are American\")\n",
    "    \n",
    "    chi2, p = results['gender_chi2']\n",
    "    print(f\"4. Framework-Gender Association: χ² = {chi2:.2f}, p = {p:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    df = df_merged.copy()\n",
    "    df = df[~df[\"desc_framework\"].isin([\"no-description\"])]\n",
    "    run_full_analysis(df)\n",
    "    # Or create sample data for testing\n",
    "    print(\"To run the analysis, load your dataframe and call:\")\n",
    "    print(\"  results = run_full_analysis(df)\")\n",
    "    print(\"\\nFor visualizations:\")\n",
    "    print(\"  plot_gender_by_framework(df, 'gender_by_framework.png')\")\n",
    "    print(\"  plot_age_by_framework(df, 'age_by_framework.png')\")\n",
    "    print(\"  plot_gender_performance_by_dataset(df, 'gender_performance.png')\")\n",
    "    print(\"  plot_age_performance_scatter(df, 'age_performance.png')\")\n",
    "    print(\"  plot_demographic_summary(df, 'demographic_summary.png')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7697a",
   "metadata": {},
   "source": [
    "## Agent Nationality Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4046dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "\n",
    "\n",
    "def iso2_to_iso3(iso2: str) -> str:\n",
    "    \"\"\"Convert ISO-2 country code to ISO-3.\"\"\"\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=iso2.upper())\n",
    "        if country:\n",
    "            return country.alpha_3\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def iso2_to_name(iso2: str) -> str:\n",
    "    \"\"\"Convert ISO-2 country code to country name.\"\"\"\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=iso2.upper())\n",
    "        if country:\n",
    "            return country.name\n",
    "    except:\n",
    "        pass\n",
    "    return iso2\n",
    "\n",
    "\n",
    "def generate_map(df, output_html, use_log_scale=True):\n",
    "    \"\"\"Generate choropleth map from a DataFrame with 'predicted_country' column.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Generate Choropleth Map from Predicted Countries\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    country_series = df[\"predicted_country\"].dropna().str.strip()\n",
    "    country_series = country_series[country_series != \"ERROR\"]\n",
    "\n",
    "    country_counts = Counter(country_series)\n",
    "    total_names = len(country_series)\n",
    "\n",
    "    print(f\"Total names: {total_names}\")\n",
    "    print(f\"Unique countries: {len(country_counts)}\")\n",
    "\n",
    "    if not country_counts:\n",
    "        print(\"ERROR: No valid country data found.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Show top 10 countries\n",
    "    print(\"\\nTop 10 countries:\")\n",
    "    for iso2, count in country_counts.most_common(10):\n",
    "        name = iso2_to_name(iso2)\n",
    "        pct = count / total_names * 100\n",
    "        print(f\"  {iso2} ({name}): {count} ({pct:.1f}%)\")\n",
    "\n",
    "    # Create DataFrame with ISO-3 codes for plotly\n",
    "    data = []\n",
    "    skipped = []\n",
    "\n",
    "    for iso2, count in country_counts.items():\n",
    "        iso3 = iso2_to_iso3(iso2)\n",
    "        if iso3:\n",
    "            entry = {\n",
    "                \"iso2\": iso2,\n",
    "                \"iso3\": iso3,\n",
    "                \"country_name\": iso2_to_name(iso2),\n",
    "                \"count\": count,\n",
    "                \"percentage\": count / total_names * 100,\n",
    "            }\n",
    "            if use_log_scale:\n",
    "                entry[\"log_count\"] = math.log10(count + 1)\n",
    "            data.append(entry)\n",
    "        else:\n",
    "            skipped.append(iso2)\n",
    "\n",
    "    if skipped:\n",
    "        print(f\"\\nSkipped (invalid ISO-2 codes): {', '.join(skipped)}\")\n",
    "\n",
    "    plot_df = pd.DataFrame(data)\n",
    "\n",
    "    color_col = \"log_count\" if use_log_scale else \"count\"\n",
    "    hover_data = {\n",
    "        \"iso3\": False,\n",
    "        \"iso2\": True,\n",
    "        \"count\": True,\n",
    "        \"percentage\": \":.1f\",\n",
    "    }\n",
    "    if use_log_scale:\n",
    "        hover_data[\"log_count\"] = False\n",
    "\n",
    "    fig = px.choropleth(\n",
    "        plot_df,\n",
    "        locations=\"iso3\",\n",
    "        locationmode=\"ISO-3\",\n",
    "        color=color_col,\n",
    "        hover_name=\"country_name\",\n",
    "        hover_data=hover_data,\n",
    "#       color_continuous_scale=\"Blues\",\n",
    "        color_continuous_scale=\"YlOrRd\",\n",
    "        title=f\"Distribution of Agent Nationalities\",\n",
    "        labels={\n",
    "            \"count\": \"Number of Names\",\n",
    "            \"percentage\": \"Percentage (%)\",\n",
    "            \"iso2\": \"ISO Code\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if use_log_scale:\n",
    "        max_count = plot_df[\"count\"].max()\n",
    "        tick_values = [1, 10, 100, 1000, 10000, 100000]\n",
    "        tick_values = [v for v in tick_values if v <= max_count + 10]\n",
    "        tickvals = [math.log10(v + 1) for v in tick_values]\n",
    "\n",
    "        fig.update_layout(\n",
    "            coloraxis_colorbar=dict(\n",
    "                title=\"Count\",\n",
    "                tickvals=tickvals,\n",
    "                ticktext=[str(v) for v in tick_values],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        geo=dict(\n",
    "            showframe=False,\n",
    "            showcoastlines=True,\n",
    "            projection_type=\"natural earth\",\n",
    "            bgcolor=\"white\",\n",
    "            landcolor=\"lightgray\",\n",
    "            showland=True,\n",
    "        ),\n",
    "        title_x=0.5,\n",
    "        margin=dict(l=0, r=0, t=50, b=0),\n",
    "        paper_bgcolor=\"white\",\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        marker_line_color=\"darkgray\",\n",
    "        marker_line_width=0.5,\n",
    "    )\n",
    "\n",
    "    fig.write_html(output_html)\n",
    "    print(f\"\\nMap saved: {output_html}\")\n",
    "\n",
    "    try:\n",
    "        fig.show(renderer=\"browser\")\n",
    "    except:\n",
    "        print(\"(Could not open browser, but HTML file is saved)\")\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c081a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Generate Choropleth Map from Predicted Countries\n",
      "==================================================\n",
      "Total names: 4784\n",
      "Unique countries: 62\n",
      "\n",
      "Top 10 countries:\n",
      "  GB (United Kingdom): 1758 (36.7%)\n",
      "  KR (Korea, Republic of): 1404 (29.3%)\n",
      "  IE (Ireland): 348 (7.3%)\n",
      "  NZ (New Zealand): 241 (5.0%)\n",
      "  UA (Ukraine): 214 (4.5%)\n",
      "  ES (Spain): 164 (3.4%)\n",
      "  CA (Canada): 133 (2.8%)\n",
      "  PT (Portugal): 59 (1.2%)\n",
      "  AU (Australia): 54 (1.1%)\n",
      "  TW (Taiwan, Province of China): 50 (1.0%)\n",
      "\n",
      "Map saved: map_linear.html\n",
      "Opening in existing browser session.\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Linear scale\n",
    "generate_map(df, \"map_linear.html\", use_log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b27c7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Generate Choropleth Map from Predicted Countries\n",
      "==================================================\n",
      "Total names: 4784\n",
      "Unique countries: 62\n",
      "\n",
      "Top 10 countries:\n",
      "  GB (United Kingdom): 1758 (36.7%)\n",
      "  KR (Korea, Republic of): 1404 (29.3%)\n",
      "  IE (Ireland): 348 (7.3%)\n",
      "  NZ (New Zealand): 241 (5.0%)\n",
      "  UA (Ukraine): 214 (4.5%)\n",
      "  ES (Spain): 164 (3.4%)\n",
      "  CA (Canada): 133 (2.8%)\n",
      "  PT (Portugal): 59 (1.2%)\n",
      "  AU (Australia): 54 (1.1%)\n",
      "  TW (Taiwan, Province of China): 50 (1.0%)\n",
      "\n",
      "Map saved: map_log.html\n",
      "Opening in existing browser session.\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Log scale (default)\n",
    "generate_map(df, \"map_log.html\", use_log_scale=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a0f32",
   "metadata": {},
   "source": [
    "## Biased Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0af9b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_biased_models(df: pd.DataFrame, variable:str, category_col: str, primary_group: str, secondary_group: str, metric_col: str = \"match\") -> list[str]:\n",
    "\n",
    "    def check_bias(group):\n",
    "        \"\"\"Helper function to apply to each model group.\"\"\"\n",
    "        try:\n",
    "            # Get the match rate for the primary group (e.g., 'male')\n",
    "            primary_match = group[group[category_col] == primary_group][metric_col].iloc[0]\n",
    "            # Get the match rate for the secondary group (e.g., 'female')\n",
    "            secondary_match = group[group[category_col] == secondary_group][metric_col].iloc[0]\n",
    "\n",
    "            # Check if primary_group performance is greater than secondary_group performance\n",
    "            return primary_match > secondary_match\n",
    "        except IndexError:\n",
    "            # Handle cases where one or both groups might be missing for a model\n",
    "            return False\n",
    "\n",
    "    group = df.groupby([variable, category_col])[metric_col].mean().reset_index()\n",
    "\n",
    "    # Apply the filtering function across all unique models\n",
    "    biased_df = group.groupby(variable).filter(check_bias)\n",
    "\n",
    "    # Return the unique list of model names from the filtered DataFrame\n",
    "    return biased_df[variable].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3d693c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results: Models where Male Match > Female Match ---\n",
      "gemma-3-12b-it\n",
      "gemma-3-27b-it\n",
      "gemma-3-4b-it\n",
      "llama-3.1-8b-instruct\n",
      "llama-3.3-70b-instruct\n",
      "llama-4-scout\n",
      "nova-micro-v1\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the function to find models biased towards 'male'\n",
    "biased_to_male = find_biased_models(\n",
    "    df=df_merged,\n",
    "    variable=\"model\",\n",
    "    category_col=\"predicted_gender\",\n",
    "    primary_group=\"male\",\n",
    "    secondary_group=\"female\",\n",
    "    metric_col=\"match\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Results: Models where Male Match > Female Match ---\")\n",
    "for model in biased_to_male:\n",
    "    print(model) # Expected: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eca485da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "      <td>female</td>\n",
       "      <td>0.691773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "      <td>male</td>\n",
       "      <td>0.720842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma-3-12b-it</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>female</td>\n",
       "      <td>0.688418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>male</td>\n",
       "      <td>0.716952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>female</td>\n",
       "      <td>0.612042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>male</td>\n",
       "      <td>0.639449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.618750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemma-3-4b-it</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>female</td>\n",
       "      <td>0.604471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>male</td>\n",
       "      <td>0.609062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.533529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.639143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>female</td>\n",
       "      <td>0.560566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>male</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.563871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>llama-3.2-3b-instruct</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>llama-3.3-70b-instruct</td>\n",
       "      <td>female</td>\n",
       "      <td>0.700643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>llama-3.3-70b-instruct</td>\n",
       "      <td>male</td>\n",
       "      <td>0.732778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>llama-3.3-70b-instruct</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>llama-3.3-70b-instruct</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.772143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>llama-4-scout</td>\n",
       "      <td>female</td>\n",
       "      <td>0.652907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>llama-4-scout</td>\n",
       "      <td>male</td>\n",
       "      <td>0.737586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>llama-4-scout</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.602500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>female</td>\n",
       "      <td>0.639187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>male</td>\n",
       "      <td>0.638857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.669444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nova-micro-v1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.708723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nova-micro-v1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.724180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nova-micro-v1</td>\n",
       "      <td>nonbinary</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nova-micro-v1</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model predicted_gender     match\n",
       "0           gemma-3-12b-it           female  0.691773\n",
       "1           gemma-3-12b-it             male  0.720842\n",
       "2           gemma-3-12b-it        uncertain  0.730000\n",
       "3           gemma-3-27b-it           female  0.688418\n",
       "4           gemma-3-27b-it             male  0.716952\n",
       "5           gemma-3-27b-it        nonbinary  0.562500\n",
       "6           gemma-3-27b-it        uncertain  0.748000\n",
       "7            gemma-3-4b-it           female  0.612042\n",
       "8            gemma-3-4b-it             male  0.639449\n",
       "9            gemma-3-4b-it        nonbinary  0.618750\n",
       "10           gemma-3-4b-it        uncertain  0.465000\n",
       "11   llama-3.1-8b-instruct           female  0.604471\n",
       "12   llama-3.1-8b-instruct             male  0.609062\n",
       "13   llama-3.1-8b-instruct        nonbinary  0.533529\n",
       "14   llama-3.1-8b-instruct        uncertain  0.639143\n",
       "15   llama-3.2-3b-instruct           female  0.560566\n",
       "16   llama-3.2-3b-instruct             male  0.520000\n",
       "17   llama-3.2-3b-instruct        nonbinary  0.563871\n",
       "18   llama-3.2-3b-instruct        uncertain  0.553000\n",
       "19  llama-3.3-70b-instruct           female  0.700643\n",
       "20  llama-3.3-70b-instruct             male  0.732778\n",
       "21  llama-3.3-70b-instruct        nonbinary  0.770000\n",
       "22  llama-3.3-70b-instruct        uncertain  0.772143\n",
       "23           llama-4-scout           female  0.652907\n",
       "24           llama-4-scout             male  0.737586\n",
       "25           llama-4-scout        uncertain  0.602500\n",
       "26            mistral-nemo           female  0.639187\n",
       "27            mistral-nemo             male  0.638857\n",
       "28            mistral-nemo        nonbinary  0.780000\n",
       "29            mistral-nemo        uncertain  0.669444\n",
       "30           nova-micro-v1           female  0.708723\n",
       "31           nova-micro-v1             male  0.724180\n",
       "32           nova-micro-v1        nonbinary  0.753333\n",
       "33           nova-micro-v1        uncertain  0.720000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = df_merged.groupby([\"model\", \"predicted_gender\"])[\"match\"].mean().reset_index()\n",
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93324c",
   "metadata": {},
   "source": [
    "## Performance by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a118dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67237/864680610.py:4: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age_bracket\n",
       "<18           NaN\n",
       "18-29    0.708000\n",
       "30-44    0.657572\n",
       "45-59    0.638573\n",
       "60+      0.679286\n",
       "Name: match, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by age bracket\n",
    "# create age brackets\n",
    "df_merged['age_bracket'] = pd.cut(df_merged['predicted_age'], bins=[0, 18, 30, 45, 60, 100], labels=['<18', '18-29', '30-44', '45-59', '60+'])\n",
    "df_merged.groupby('age_bracket')['match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "13ca634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_bracket\n",
       "45-59    2285\n",
       "60+      1848\n",
       "30-44     622\n",
       "18-29      15\n",
       "<18         0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"age_bracket\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214b70b",
   "metadata": {},
   "source": [
    "## Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "18edbb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_country\n",
       "PE    0.747692\n",
       "AU    0.715000\n",
       "FR    0.707368\n",
       "IE    0.700172\n",
       "DE    0.698182\n",
       "GB    0.682793\n",
       "UA    0.681963\n",
       "NZ    0.674025\n",
       "PT    0.663559\n",
       "TT    0.662500\n",
       "DK    0.661290\n",
       "JM    0.635833\n",
       "UY    0.632766\n",
       "TW    0.630000\n",
       "KR    0.621054\n",
       "CA    0.611579\n",
       "CH    0.576667\n",
       "ES    0.568537\n",
       "IN    0.556154\n",
       "Name: match, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = df_merged[\"predicted_country\"].value_counts().reset_index()\n",
    "df_count\n",
    "# filter those nationality with count > 10\n",
    "freq_nat = df_count[df_count[\"count\"] > 10][\"predicted_country\"].unique()\n",
    "\n",
    "df_freq_nat = df_merged[df_merged[\"predicted_country\"].isin(freq_nat)]\n",
    "df_freq_nat.groupby('predicted_country')['match'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bda58",
   "metadata": {},
   "source": [
    "## Rachel Kim Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0de2955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Dr. Rachel Kim             1232\n",
       "Rachel Kim                  106\n",
       "Dr. Jonathan Lee             44\n",
       "Dr. Elara Lee                 8\n",
       "Dr. Ethan Kim                 4\n",
       "Dr. Carl Jung                 2\n",
       "Dr. Eleanor Jung              1\n",
       "Dr. Benjamin Lee              1\n",
       "The name is: Rachel Kim       1\n",
       "Carl Jung                     1\n",
       "Jung                          1\n",
       "Elara Lee                     1\n",
       "Dr. Kim                       1\n",
       "Dr. Rachel Lee                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kor = df_merged[df_merged[\"predicted_country\"] == \"KR\"]\n",
    "df_kor[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "88dbbd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "llama-3.2-3b-instruct     463\n",
       "llama-3.1-8b-instruct     318\n",
       "llama-3.3-70b-instruct    311\n",
       "llama-4-scout             246\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kor = df_merged[df_merged[\"predicted_country\"] == \"KR\"]\n",
    "# 95 % of the names are \"Rachel Kim\" or \"Dr. Rachel Kim\"\n",
    "(df_kor[\"name\"].value_counts()[\"Dr. Rachel Kim\"] + df_kor[\"name\"].value_counts()[\"Rachel Kim\"]) / df_kor.shape[0]\n",
    "\n",
    "# df[(df_kor[\"name\"] == \"Dr. Rachel Kim\") | (df_kor[\"name\"] == \"Rachel Kim\")]\n",
    "df_kor[(df_kor[\"name\"] == \"Dr. Rachel Kim\") | (df_kor[\"name\"] == \"Rachel Kim\")][\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1541fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967885816235504"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_models = [\"llama-3.1-8b-instruct\", \"llama-3.2-3b-instruct\", \"llama-3.3-70b-instruct\", \"llama-4-scout\"]\n",
    "df_llama = df_merged[df_merged[\"model\"].isin(llama_models)]\n",
    "\n",
    "df_llama[(df_llama[\"name\"] == \"Dr. Rachel Kim\") | (df_llama[\"name\"] == \"Rachel Kim\")].shape[0] / df_llama.shape[0]\n",
    "# 0.5967885816235504, around 60% of the llama profiles are \"Rachel Kim\" or \"Dr. Rachel Kim\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b81055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Dr. Alistair Finch             678\n",
       "Dr. Vivian Holloway            260\n",
       "Dr. Emma Taylor                 85\n",
       "Professor Silas Blackwood       70\n",
       "Dr. Silas Blackwood             67\n",
       "                              ... \n",
       "Oliver 'Ollie' Kent              1\n",
       "Dr. Benjamin 'Ben' Sinclair      1\n",
       "Dr. Eleanor Thornfield           1\n",
       "Dr. Silas Vance                  1\n",
       "Dr. Eleanor Hartfield            1\n",
       "Name: count, Length: 115, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_au = df_merged[df_merged[\"predicted_country\"] == \"GB\"]\n",
    "df_au[\"name\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "42b47b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "gemma-3-12b-it    141\n",
       "gemma-3-4b-it     106\n",
       "gemma-3-27b-it     19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_au[(df_au[\"name\"] == \"Dr. Alistair Finch\") | (df_au[\"name\"] == \"Alistair Finch\")][\"model\"].value_counts()\n",
    "df_au[(df_au[\"name\"] == \"Dr. Vivian Holloway\") | (df_au[\"name\"] == \"Vivian Holloway\")][\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c46373bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "gemma-3-12b-it    131\n",
       "gemma-3-27b-it     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"name\"].value_counts().head(20)\n",
    "df_merged[df_merged[\"name\"] == \"Dr. Eleanor Vance\"][\"model\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
